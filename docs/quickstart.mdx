---
title: "Quick Start"
description: "Get up and running with context-window in under 5 minutes"
---

## Prerequisites

Before you begin, make sure you have:

<CardGroup cols={3}>
  <Card title="Node.js 18+" icon="node-js">
    [Download here](https://nodejs.org/)
  </Card>
  <Card title="OpenAI Account" icon="key">
    [Sign up](https://platform.openai.com/signup)
  </Card>
  <Card title="Pinecone Account" icon="database">
    [Sign up](https://www.pinecone.io/)
  </Card>
</CardGroup>

## Installation

<Steps>
  <Step title="Install the package">
    Install context-window using npm or your preferred package manager:

    ```bash
    npm install context-window
    ```
  </Step>

  <Step title="Create a Pinecone Index">
    First-time setup requires creating a Pinecone index:

    1. Go to [Pinecone Console](https://app.pinecone.io/)
    2. Click **Create Index**
    3. Configure your index:
       - **Name**: `context-window` (or any name you prefer)
       - **Dimensions**: `1536` (required for OpenAI embeddings)
       - **Metric**: `cosine` (recommended)
       - **Cloud**: AWS or GCP (AWS us-east-1 for free tier)
    4. Click **Create Index**

    <Note>
      The free tier includes 1 serverless index with 100K vectors, perfect for testing and small projects.
    </Note>
  </Step>

  <Step title="Get your API keys">
    You'll need API keys from both OpenAI and Pinecone:

    <Accordion title="OpenAI API Key">
      1. Visit [OpenAI API Keys](https://platform.openai.com/api-keys)
      2. Click **Create new secret key**
      3. Copy the key (starts with `sk-...`)
      4. Store it securely - you won't be able to see it again
    </Accordion>

    <Accordion title="Pinecone API Key">
      1. Visit [Pinecone Console](https://app.pinecone.io/)
      2. Go to **API Keys** in the left sidebar
      3. Copy your API key
      4. Note your environment/region (e.g., `us-east-1`)
    </Accordion>
  </Step>

  <Step title="Configure environment variables">
    Create a `.env` file in your project root:

    ```bash
    # OpenAI Configuration
    OPENAI_API_KEY=sk-...

    # Pinecone Configuration
    PINECONE_API_KEY=...
    PINECONE_INDEX=context-window
    PINECONE_ENVIRONMENT=us-east-1
    ```

    <Warning>
      Never commit your `.env` file to version control. Add it to `.gitignore`.
    </Warning>
  </Step>
</Steps>

## Your First Context Window

Let's create your first RAG application:

<Steps>
  <Step title="Create your code file">
    Create a new file `index.js` (or `index.ts` for TypeScript):

    ```typescript
    import { createContextWindow } from "context-window";

    async function main() {
      // Create a context window with your documents
      const cw = await createContextWindow({
        indexName: "my-first-context",
        data: ["./documents"],  // Path to your documents folder
        ai: {
          provider: "openai",
          model: "gpt-4o-mini"
        },
        vectorStore: {
          provider: "pinecone"
        }
      });

      // Ask a question
      const result = await cw.ask("What are the main topics in these documents?");

      console.log("Answer:", result.text);
      console.log("Sources:", result.sources);
    }

    main().catch(console.error);
    ```

    <Tip>
      You can pass a single file, multiple files, or entire directories to the `data` parameter.
    </Tip>
  </Step>

  <Step title="Prepare your documents">
    Create a `documents` folder with some sample files:

    ```bash
    mkdir documents
    echo "Context-window is a RAG library for Node.js." > documents/intro.txt
    echo "It supports PDF, Markdown, and text files." > documents/features.txt
    ```

    <Note>
      Supported formats: `.txt`, `.md`, `.pdf`
    </Note>
  </Step>

  <Step title="Run your application">
    Execute your code:

    ```bash
    node index.js
    ```

    You should see output like:

    ```
    Answer: The main topics include context-window as a RAG library
    for Node.js, with support for PDF, Markdown, and text files.
    Sources: ["intro.txt", "features.txt"]
    ```

    <Check>
      Congratulations! You've created your first RAG application with context-window.
    </Check>
  </Step>
</Steps>

## Understanding What Happened

Here's what context-window did behind the scenes:

1. **Ingested** your documents by reading all `.txt`, `.md`, and `.pdf` files
2. **Chunked** the text into overlapping segments (default: 1000 chars)
3. **Embedded** each chunk using OpenAI's text-embedding-3-small
4. **Stored** vectors in your Pinecone index
5. **Retrieved** relevant chunks when you asked a question
6. **Generated** an answer using GPT-4o-mini with strict RAG instructions

## Next Steps

<CardGroup cols={2}>
  <Card title="Explore Use Cases" icon="lightbulb" href="/use-cases">
    See real-world applications and examples
  </Card>
  <Card title="API Reference" icon="code" href="/api-reference/introduction">
    Learn about all available options and methods
  </Card>
  <Card title="Best Practices" icon="star" href="/best-practices">
    Optimize chunk size, retrieval, and performance
  </Card>
  <Card title="Examples" icon="book" href="/examples">
    Browse complete code examples for common scenarios
  </Card>
</CardGroup>

## Common Customizations

### Using Different Models

```typescript
const cw = await createContextWindow({
  indexName: "my-docs",
  data: ["./docs"],
  ai: {
    provider: "openai",
    model: "gpt-4o"  // Use GPT-4 for better accuracy
  },
  vectorStore: { provider: "pinecone" }
});
```

### Adjusting Chunk Size

```typescript
const cw = await createContextWindow({
  indexName: "my-docs",
  data: ["./docs"],
  chunk: {
    size: 1500,    // Larger chunks for more context
    overlap: 200   // More overlap to preserve continuity
  },
  ai: { provider: "openai" },
  vectorStore: { provider: "pinecone" }
});
```

### Fine-tuning Retrieval

```typescript
const cw = await createContextWindow({
  indexName: "my-docs",
  data: ["./docs"],
  limits: {
    topK: 5,               // Retrieve top 5 most relevant chunks
    scoreThreshold: 0.7,   // Only use high-confidence matches
    maxContextChars: 6000  // Limit context size
  },
  ai: { provider: "openai" },
  vectorStore: { provider: "pinecone" }
});
```

## Troubleshooting

<AccordionGroup>
  <Accordion title="Error: Pinecone index not found">
    Make sure:
    - Your Pinecone index exists in the console
    - `PINECONE_INDEX` in `.env` matches your index name
    - You're using the correct environment/region
  </Accordion>

  <Accordion title="Error: Incorrect dimensions">
    Your Pinecone index must have **1536 dimensions**. If you created it with wrong dimensions:
    1. Delete the old index in Pinecone Console
    2. Create a new one with 1536 dimensions
    3. Re-run your ingestion
  </Accordion>

  <Accordion title="Error: Invalid API key">
    Verify your API keys:
    - OpenAI key starts with `sk-`
    - Keys are correctly set in `.env`
    - No extra spaces or quotes around the keys
  </Accordion>

  <Accordion title='Always returns "I don\'t know"'>
    Try:
    - Lowering `scoreThreshold` or removing it entirely
    - Increasing `topK` to retrieve more chunks
    - Rephrasing your question to match document content
    - Verifying documents were ingested successfully
  </Accordion>
</AccordionGroup>

<Note>
  Need more help? Check out the [Troubleshooting guide](/troubleshooting) or open an issue on [GitHub](https://github.com/hamittokay/context-window/issues).
</Note>
